{
  "machine": {
    "gpu": 1,
    "cpu": 4000,
    "ram": 16000
  },
  "job": {
    "APIVersion": "V1beta1",
    "Spec": {
      "Deal": {
        "Concurrency": 1
      },
      "Docker": {
        "Entrypoint": [
          "/bin/sh",
          "-c",
          "curl -fsSL https://nvidia.github.io/libnvidia-container/gpgkey | gpg --dearmor -o /usr/share/keyrings/nvidia-container-toolkit-keyring.gpg && curl -s -L https://nvidia.github.io/libnvidia-container/stable/deb/nvidia-container-toolkit.list | sed 's#deb https://#deb [signed-by=/usr/share/keyrings/nvidia-container-toolkit-keyring.gpg] https://#g' | tee /etc/apt/sources.list.d/nvidia-container-toolkit.list && apt-get update && apt-get install -y nvidia-container-toolkit && nvidia-ctk runtime configure --runtime=docker && systemctl restart docker && docker run -d --gpus=all -v ollama:/root/.ollama -p 11434:11434 --name ollama ollama/ollama && docker exec -it ollama ollama run llama3"
        ],
        "EnvironmentVariables": [
          "CUDA_VERSION=11.3.1",
          "ROCM_VERSION=6.0.2",
          "GOLANG_VERSION=1.22.1",
          "CMAKE_VERSION=3.22.1"
        ],
        "Image": "ubuntu:22.04"
      },
      "Engine": "Docker",
      "Network": {
        "Type": "None"
      },
      "PublisherSpec": {
        "Type": "IPFS"
      },
      "Resources": {
        "GPU": "all"
      },
      "Timeout": 3600,
      "Verifier": "Noop"
    }
  }
}